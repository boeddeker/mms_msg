{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paderbox as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34534828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "from mms_msg.visualization.plot import plot_mixture\n",
    "from mms_msg import keys\n",
    "from mms_msg.simulation.utils import load_audio\n",
    "        \n",
    "def plot_mixtures(generator_dataset, number=6, columns=3, figure_width=10):\n",
    "    with pb.visualization.axes_context(columns=columns, figure_size=(figure_width, 3)) as ac:\n",
    "        for ex in itertools.islice(generator_dataset, number):\n",
    "            plot_mixture(ex, ax=ac.new)\n",
    "            # activity = defaultdict(pb.array.interval.zeros)\n",
    "            # num_samples = pb.utils.nested.get_by_path(ex, 'num_samples.original_source', allow_early_stopping=True)\n",
    "            # for o, l, s in zip(ex['offset']['original_source'], num_samples, ex['speaker_id']):\n",
    "            #     activity[s][o:o+l] = True\n",
    "            #\n",
    "            # pb.visualization.plot.activity(activity, ax=ac.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a35c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mms_msg\n",
    "from mms_msg import sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29960a24",
   "metadata": {},
   "source": [
    "## Preparation: The input dataset\n",
    "The mixture/meeting generators are generic, i.e., they work with any database that contains examples of single-speaker speech.\n",
    "The input database has to have its examples in the correct format, i.e., they have to contain the correct keys.\n",
    "\n",
    "The examples have to have the following format:\n",
    " - `example_id` (`str`): The ID of the input example. Has to be unique in the input dataset\n",
    " - `num_samples` or `num_samples.observation` (`int`): The number of samples in the example\n",
    " - `speaker_id` (`str`): The ID of the speaker that uttered the speech in this example\n",
    " - `audio_path` or `audio_path.observation` (`str`): The path to the audio, will later be in `audio_path.original_source`\n",
    " \n",
    "For meeting data additionally:\n",
    " - `scenario` (`str`): An identifier that uniquely identifies a \"scenario\" that should not change for a single speaker in a meeting. E.g., in LibriSpeech the scenario should be `f\"{chapter_id}_{speaker_id}\"`. Defaults to `speaker_id`.\n",
    "\n",
    "All other keys are simply copied over from the input examples, so all information present in the input examples will be present in the generated mixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7794176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input datasets. Use LibriSpeech here because it is freely available, but WSJ (or any other database) works as well\n",
    "from mms_msg.databases.single_speaker.librispeech.database import LibriSpeech8kHz\n",
    "input_db = LibriSpeech8kHz()\n",
    "input_ds = input_db.get_dataset('test_clean')\n",
    "input_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f7ee4",
   "metadata": {},
   "source": [
    "## Fully overlapped mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51fb91",
   "metadata": {},
   "source": [
    "### Like WSJ0-2mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic, anechoic, no offset, like WSJ0-2mix\n",
    "\n",
    "# Compute a composition of base examples. This makes sure that the speaker distribution\n",
    "# in the mixtures is equal to the speaker distribution in the original database.\n",
    "ds = sampling.source_composition.get_composition_dataset(input_dataset=input_ds, num_speakers=2)\n",
    "\n",
    "# If required: Offset the utterances\n",
    "ds = ds.map(sampling.pattern.classical.ConstantOffsetSampler(0))\n",
    "\n",
    "# If required: Add log_weights to simulate volume differences\n",
    "ds = ds.map(sampling.environment.scaling.UniformScalingSampler(max_weight=5))\n",
    "\n",
    "# If required: Truncate to the shorter utterance\n",
    "ds = ds.map(mms_msg.simulation.truncation.truncate_min)\n",
    "\n",
    "len(ds), ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495036e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mixtures(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92352e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load audio\n",
    "from mms_msg import keys\n",
    "ds = ds\\\n",
    "    .map(lambda example: load_audio(example, keys.ORIGINAL_SOURCE))\\\n",
    "    .map(mms_msg.simulation.anechoic.anechoic_scenario_map_fn)\n",
    "ex = ds[0]\n",
    "pb.io.play(ex['audio_data']['observation'], sample_rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6c614",
   "metadata": {},
   "source": [
    "### Like SMS-WSJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46323d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mms_msg.databases.reverberation.sms_wsj import SMSWSJRIRDatabase\n",
    "ds = sampling.source_composition.get_composition_dataset(input_dataset=input_ds, num_speakers=2)\n",
    "ds = ds.map(sampling.pattern.classical.SMSWSJOffsetSampler())\n",
    "ds = ds.map(sampling.environment.scaling.UniformScalingSampler(max_weight=5))\n",
    "ds = ds.map(sampling.environment.noise.UniformSNRSampler(20, 30))\n",
    "ds = ds.map(sampling.environment.rir.RIRSampler(SMSWSJRIRDatabase().get_dataset('test_eval92')))\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c113246",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mixtures(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ad261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example\n",
    "from mms_msg import keys\n",
    "ds = ds\\\n",
    "    .map(lambda example: load_audio(example, keys.ORIGINAL_SOURCE, keys.RIR))\\\n",
    "    .map(mms_msg.simulation.reverberant.reverberant_scenario_map_fn)\\\n",
    "    .map(mms_msg.simulation.noise.white_microphone_noise)\n",
    "ex = ds[0]\n",
    "pb.io.play(ex['audio_data']['observation'], sample_rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38a255",
   "metadata": {},
   "source": [
    "### Dynamic Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic mixing: Set the rng argument to `True` to get a non-deterministic dataset that changes its contents \n",
    "# every time it is iterated. Useful if you want to train on an infinite stream of randomly generated examples\n",
    "# TODO: dynamic_ -> rng\n",
    "ds = sampling.source_composition.get_composition_dataset(input_dataset=input_ds, num_speakers=2, rng=True)\n",
    "# only the function above this line changed from the determinstic case\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# the part below this line is deterministic and equal to the cell above\n",
    "ds = ds.map(sampling.pattern.classical.SMSWSJOffsetSampler())\n",
    "ds = ds.map(sampling.environment.scaling.UniformScalingSampler(max_weight=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368444fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that iterating two times gives different examples\n",
    "for _ in range(2):\n",
    "    plot_mixtures(ds, number=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f127e5",
   "metadata": {},
   "source": [
    "## Generate Meetings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0e521",
   "metadata": {},
   "source": [
    "### Anechoic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5fd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic, anechoic, use the same base function as for SMS-WSJ, i.e., we have the same initial examples as SMS-WSJ\n",
    "ds = sampling.source_composition.get_composition_dataset(input_dataset=input_ds, num_speakers=[3, 4, 5])\n",
    "ds = ds.map(sampling.environment.scaling.UniformScalingSampler(max_weight=5))\n",
    "ds = ds.map(sampling.pattern.meeting.MeetingSampler(duration=60*8000)(input_ds))\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c68422",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mixtures(ds, columns=2, figure_width=20, number=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101a5b0",
   "metadata": {},
   "source": [
    "### With reverberation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With rir, use the same base function as for SMS-WSJ, i.e., we have the same initial examples as SMS-WSJ\n",
    "import functools\n",
    "ds = sampling.source_composition.get_composition_dataset(input_dataset=input_ds, num_speakers=[3, 4])\n",
    "ds = ds.map(sampling.environment.scaling.UniformScalingSampler(max_weight=5))\n",
    "ds = ds.map(sampling.environment.rir.RIRSampler(SMSWSJRIRDatabase().get_dataset('test_eval92')))\n",
    "ds = ds.map(sampling.pattern.meeting.MeetingSampler(duration=60*8000)(input_ds))\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94332d",
   "metadata": {},
   "source": [
    "## Class-based interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b657d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mms_msg.databases.classical.full_overlap.Libri2MixClean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset names are the same as LibriSpeech\n",
    "db.dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mixtures(db.get_dataset('test_clean'), number=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4290e3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dynamic mixing can be enabled by appending \"_rng\" (for a random seed) or \"_rng<seed>\" (for a fixed seed) to the dataset name.\n",
    "# The top two potted rows are different because the seed is random by default\n",
    "# The bottom two plotted rows are equal because the seed is fixed to 42\n",
    "plot_mixtures(db.get_dataset('train_clean_100_rng'), number=3)\n",
    "plot_mixtures(db.get_dataset('train_clean_100_rng'), number=3)\n",
    "plot_mixtures(db.get_dataset('train_clean_100_rng42'), number=3)\n",
    "plot_mixtures(db.get_dataset('train_clean_100_rng42'), number=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Audio can be loaded with the `load_example` method of the database object\n",
    "ex = db.load_example(db.get_dataset('test_clean')[0])\n",
    "pb.io.play(ex['audio_data']['observation'], name='observation')\n",
    "pb.io.play(ex['audio_data']['speech_image'][0], name='speech_image 1')\n",
    "pb.io.play(ex['audio_data']['speech_image'][1], name='speech_image 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874d62d",
   "metadata": {},
   "source": [
    "## Generate JSON\n",
    "A JSON file that contains the hyperparameters and can be read with a `lazy_dataset.JSONDatabase` object can easily be created by iterating over the dataset.\n",
    "If you want to dump all generated signals as audio files, refer to TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b593a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "database_dict = {'datasets': {dataset_name: dict(tqdm(db.get_dataset(dataset_name).items(), desc=dataset_name)) for dataset_name in db.dataset_names}}\n",
    "pb.io.dump(database_dict, 'libri_mix.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d3326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (padertorch)",
   "language": "python",
   "name": "padertorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}